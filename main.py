import os
import json
import logging
import requests
import time
import datetime
import sys
import re
from bs4 import BeautifulSoup
from groq import Groq
from typing import Dict, Any, Optional, Tuple

# ==============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ==============================================================================

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger("Tracen_Intel_Center")

ROLE_NEWS = "1440444308506280210"
ROLE_BANNER = "1439787310831894679"

JP_URL = "https://umamusume.jp/news/"
# –ì–ª–æ–±–∞–ª —á–∞—Å—Ç–æ –º–µ–Ω—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –∞–Ω–æ–Ω—Å–∞–º
GLOBAL_URL = "https://uma.kakaogames.com/news/all" 

DB_JP = "last_id_jp.txt"
DB_GL = "last_id_gl.txt"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
GROQ_KEY = os.environ.get("GROQ_API_KEY")
WEBHOOK = os.environ.get("DISCORD_WEBHOOK")

if not GROQ_KEY or not WEBHOOK:
    logger.critical("–û–®–ò–ë–ö–ê: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–µ–∫—Ä–µ—Ç—ã GitHub (GROQ_API_KEY –∏ DISCORD_WEBHOOK)!")
    sys.exit(1)

client = Groq(api_key=GROQ_KEY)

# ==============================================================================
# –ú–û–î–£–õ–¨ –°–ö–ê–ù–ï–†–ê (–£–õ–£–ß–®–ï–ù–ù–´–ô)
# ==============================================================================

class TracenScanner:
    def __init__(self, region: str, url: str, db: str):
        self.region = region
        self.url = url
        self.db = db
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }

    def get_latest(self) -> Optional[Dict[str, str]]:
        try:
            r = requests.get(self.url, headers=self.headers, timeout=25)
            r.raise_for_status()
            soup = BeautifulSoup(r.text, 'html.parser')
            
            if "Japan" in self.region:
                # –ü–æ–∏—Å–∫ –≤ —è–ø–æ–Ω—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
                item = soup.select_one('.news-list__item')
                if not item: return None
                
                link_tag = item.find('a')
                if not link_tag: return None
                
                link = "https://umamusume.jp" + link_tag['href']
                img_tag = item.find('img')
                img = img_tag['src'] if img_tag else None
                news_id = link.split('=')[-1]
                
            else:
                # –ü–æ–∏—Å–∫ –≤ –≥–ª–æ–±–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ (Kakao)
                item = soup.select_one('.article_list li') or soup.select_one('tr') or soup.select_one('.news_item')
                if not item: return None
                
                link_tag = item.find('a')
                if not link_tag: return None
                
                link = link_tag['href']
                if not link.startswith('http'):
                    link = "https://uma.kakaogames.com" + link
                
                img = None # –ì–ª–æ–±–∞–ª —Ä–µ–¥–∫–æ –¥–∞–µ—Ç –ø—Ä–µ–≤—å—é –≤ —Å–ø–∏—Å–∫–µ
                news_id = link.rstrip('/').split('/')[-1]

            return {"id": str(news_id), "url": link, "img": img}
        except Exception as e:
            logger.error(f"[{self.region}] –û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return None

    def is_new(self, news_id: str) -> bool:
        if not os.path.exists(self.db):
            with open(self.db, 'w') as f: f.write("0")
            return True
        with open(self.db, 'r') as f:
            return f.read().strip() != news_id

    def save(self, news_id: str):
        with open(self.db, 'w') as f: f.write(news_id)

# ==============================================================================
# –ò–ò-–ê–ù–ê–õ–ò–ó–ê–¢–û–† (–£–õ–¨–¢–†–ê)
# ==============================================================================

class MultiRegionAI:
    @staticmethod
    def analyze(raw_html: str, region: str) -> Dict[str, Any]:
        # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Ç–µ–≥–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
        soup = BeautifulSoup(raw_html, 'html.parser')
        text = soup.get_text(separator=' ', strip=True)[:5000]

        prompt = f"""
        –¢—ã ‚Äî –ì–ª–∞–≤–Ω—ã–π –ê–Ω–∞–ª–∏—Ç–∏–∫ Tracen Academy. –¢–≤–æ—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ‚Äî –∏–≥—Ä–∞ 'Uma Musume: Pretty Derby'.
        –†–ï–ì–ò–û–ù –î–ê–ù–ù–´–•: {region}
        
        –ó–ê–î–ê–ß–ê:
        1. –ù–∞–∑–Ω–∞—á—å RANK (S/A/B/C) –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏.
        2. –ü–µ—Ä–µ–≤–µ–¥–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞ —Ä—É—Å—Å–∫–∏–π.
        3. –≠—Ç–æ –ë–ê–ù–ù–ï–† (–≥–∞—á–∞) –∏–ª–∏ –≤–∞–∂–Ω—ã–π –°–õ–ò–í? (True/False).
        4. –°–¥–µ–ª–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä (–¥–∞—Ç—ã, –∫–∞–º–Ω–∏, –Ω–æ–≤—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏).
        5. –î–∞–π –ø—Ä–æ–≥–Ω–æ–∑: —á—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏–≥—Ä—ã.

        –û–¢–í–ï–¢–¨ –°–¢–†–û–ì–û JSON:
        {{
            "rank": "...", "title": "...", "is_banner": bool,
            "summary": "–ö—Ä–∞—Ç–∫–∞—è —Å—É—Ç—å", "details": "–î–µ—Ç–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫",
            "future": "–ü—Ä–æ–≥–Ω–æ–∑", "verdict": "–°–æ–≤–µ—Ç —Ç—Ä–µ–Ω–µ—Ä—É"
        }}
        """
        try:
            res = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            return json.loads(res.choices[0].message.content)
        except Exception as e:
            logger.error(f"AI Error: {e}")
            return {"rank": "B", "title": "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞", "is_banner": False, 
                    "summary": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç", "details": "N/A", "future": "N/A", "verdict": "N/A"}

# ==============================================================================
# –õ–û–ì–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò
# ==============================================================================

def process_region(name, url, db):
    scanner = TracenScanner(name, url, db)
    meta = scanner.get_latest()
    
    if meta and scanner.is_new(meta["id"]):
        logger.info(f"[{name}] –ù–∞–π–¥–µ–Ω–∞ –Ω–æ–≤–∞—è –∑–∞–ø–∏—Å—å: {meta['id']}")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç–∞—Ç—å–∏
        try:
            content_page = requests.get(meta["url"], timeout=20).text
        except:
            content_page = "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É."

        analysis = MultiRegionAI.analyze(content_page, name)
        
        # –ü–∏–Ω–≥–∏ –∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ
        ping = f"<@&{ROLE_NEWS}>"
        if analysis.get("is_banner") or analysis.get("rank") == "S":
            ping += f" <@&{ROLE_BANNER}>"
            
        color = {"S": 0xFFD700, "A": 0xFF4500, "B": 0xDA70D6, "C": 0x5DADE2}.get(analysis["rank"], 0x99AAB5)
        
        embed_data = {
            "content": f"üì¢ **–û–ü–ï–†–ê–¢–ò–í–ù–´–ô –û–¢–ß–ï–¢: {name.upper()}**\n{ping}",
            "embeds": [{
                "title": f"‚Äî ‚ú¶ RANK: {analysis['rank']} | {analysis['title']} ‚ú¶ ‚Äî",
                "description": (
                    f"**{analysis['summary']}**\n\n"
                    f"‚ï≠‚îÄ‚îÄ‚îÄ ‚≠ê **–ê–ù–ê–õ–ò–ó ({name})**\n"
                    f"‚îÇ {analysis['details']}\n"
                    "‚îÇ\n"
                    f"‚îÇ ‚ñ∏ **–ü–†–û–ì–ù–û–ó–´ –ò –°–õ–ò–í–´**\n"
                    f"‚îÇ üîÆ {analysis['future']}\n"
                    "‚îÇ\n"
                    f"‚îÇ ‚ñ∏ **–í–ï–†–î–ò–ö–¢**\n"
                    f"‚îÇ ‚úÖ {analysis['verdict']}\n"
                    f"‚ï∞‚îÄ‚îÄ‚îÄ üîó [–û–†–ò–ì–ò–ù–ê–õ]({meta['url']})"
                ),
                "color": color,
                "image": {"url": meta["img"]} if meta["img"] else {},
                "footer": {"text": f"Region: {name} | Tracen Intelligence Unit"},
                "timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat()
            }]
        }
        
        response = requests.post(WEBHOOK, json=embed_data)
        if response.status_code < 300:
            scanner.save(meta["id"])
            logger.info(f"[{name}] –£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ.")

def main():
    # –Ø–ø–æ–Ω–∏—è
    process_region("Japan", JP_URL, DB_JP)
    time.sleep(5) # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Ä–µ–≥–∏–æ–Ω–∞–º–∏
    # –ì–ª–æ–±–∞–ª
    process_region("Global", GLOBAL_URL, DB_GL)

if __name__ == "__main__":
    main()
