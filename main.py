import os
import json
import logging
import requests
import time
import datetime
import sys
import re
from bs4 import BeautifulSoup
from groq import Groq
from typing import Dict, Any, Optional, Tuple

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è GitHub Actions (–≤—ã–≤–æ–¥ —Å—Ä–∞–∑—É –≤ –∫–æ–Ω—Å–æ–ª—å)
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s', stream=sys.stdout)
logger = logging.getLogger("Tracen_Intelligence")

# –†–æ–ª–∏ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
ROLE_NEWS = "1440444308506280210"
ROLE_BANNER = "1439787310831894679"

# –ö–æ–Ω—Ñ–∏–≥–∏ URL
JP_URL = "https://umamusume.jp/news/"
GLOBAL_URL = "https://www.crunchyroll.com/news" 

DB_JP = "last_id_jp.txt"
DB_GL = "last_id_gl.txt"

GROQ_KEY = os.environ.get("GROQ_API_KEY")
WEBHOOK = os.environ.get("DISCORD_WEBHOOK")

if not GROQ_KEY or not WEBHOOK:
    print("!!! –û–®–ò–ë–ö–ê: –ü—Ä–æ–≤–µ—Ä—å —Å–µ–∫—Ä–µ—Ç—ã GROQ_API_KEY –∏ DISCORD_WEBHOOK –≤ GitHub !!!", flush=True)
    sys.exit(1)

client = Groq(api_key=GROQ_KEY)

class TracenScanner:
    def __init__(self, region_name: str, base_url: str, db_file: str):
        self.region = region_name
        self.url = base_url
        self.db_file = db_file
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }

    def get_latest(self) -> Optional[Dict[str, str]]:
        try:
            print(f"--- –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ {self.region}... ---", flush=True)
            r = requests.get(self.url, headers=self.headers, timeout=25)
            r.raise_for_status()
            soup = BeautifulSoup(r.text, 'html.parser')
            
            if "Japan" in self.region:
                # –ú–ï–•–ê–ù–ò–ó–ú –£–°–ò–õ–ï–ù–ù–û–ì–û –ü–û–ò–°–ö–ê (JP)
                item = soup.select_one('.news-list__item')
                if not item:
                    item = soup.find('a', href=re.compile(r'detail\.php\?id=\d+'))
                if not item:
                    item = soup.select_one('li[class*="news"]')

                if not item: 
                    print(f"DEBUG: –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ JP –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–æ–≤–æ—Å—Ç–∏. –ü—Ä–æ–≤–µ—Ä—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–∞–π—Ç–∞.", flush=True)
                    return None
                
                link_tag = item if item.name == 'a' else item.find('a')
                if not link_tag: return None
                
                href = link_tag['href']
                link = "https://umamusume.jp" + href if href.startswith('/') else href
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å—Ç—ã–π —Ü–∏—Ñ—Ä–æ–≤–æ–π ID
                news_id_match = re.search(r'id=(\d+)', link)
                news_id = news_id_match.group(1) if news_id_match else link.split('/')[-1]
                
                img_tag = item.find('img') if hasattr(item, 'find') else None
                img = img_tag['src'] if img_tag else None
                
                return {"id": str(news_id), "url": link, "img": img}
            
            else:
                # –ü–û–ò–°–ö –î–õ–Ø GLOBAL (CRUNCHYROLL)
                links = soup.find_all('a', href=True)
                for a in links:
                    href = a['href'].lower()
                    if "uma-musume" in href or "pretty-derby" in href:
                        l = a['href'] if a['href'].startswith('http') else "https://www.crunchyroll.com" + a['href']
                        id_val = l.rstrip('/').split('/')[-1]
                        return {"id": str(id_val), "url": l, "img": None}
                return None
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–∫–∞–Ω–µ—Ä–∞ {self.region}: {e}", flush=True)
            return None

    def check_new(self, current_id: str) -> bool:
        if not os.path.exists(self.db_file): 
            with open(self.db_file, 'w') as f: f.write("EMPTY")
            return True
        with open(self.db_file, 'r') as f:
            old_id = f.read().strip()
            print(f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª—è {self.region}: –°—Ç–∞—Ä—ã–π({old_id}) vs –ù–æ–≤—ã–π({current_id})", flush=True)
            return old_id != current_id

    def save_id(self, current_id: str):
        with open(self.db_file, 'w') as f: f.write(str(current_id))

class MultiRegionAI:
    @staticmethod
    def analyze(text: str, region: str) -> Dict[str, Any]:
        print(f"--- –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ –ò–ò ({region}) ---", flush=True)
        prompt = f"""
        –¢—ã ‚Äî –≥–ª–∞–≤–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ Tracen Intelligence. –°–¥–µ–ª–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä –Ω–∞ —Ä—É—Å—Å–∫–æ–º.
        –†–ï–ì–ò–û–ù: {region}
        –ó–ê–î–ê–ß–ê:
        1. –û–ø—Ä–µ–¥–µ–ª–∏ –†–∞–Ω–≥ (S/A/B/C).
        2. –≠—Ç–æ –±–∞–Ω–Ω–µ—Ä –∏–ª–∏ –≤–∞–∂–Ω—ã–π –∞–Ω–æ–Ω—Å? (True/False).
        3. –°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –∏ –µ–º–∫–∏–π —Ä–∞–∑–±–æ—Ä.
        –í–ï–†–ù–ò –°–¢–†–û–ì–û JSON:
        {{
            "rank": "...", "title": "...", "is_banner": bool,
            "summary": "...", "details": "...", "future": "...", "verdict": "..."
        }}
        –¢–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏: {text[:4500]}
        """
        res = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        return json.loads(res.choices[0].message.content)

def process_region(region_name, url, db_file):
    scanner = TracenScanner(region_name, url, db_file)
    meta = scanner.get_latest()
    
    if meta and scanner.check_new(meta["id"]):
        print(f"!!! –û–ë–ù–ê–†–£–ñ–ï–ù–ê –ù–û–í–ê–Ø –ê–ö–¢–ò–í–ù–û–°–¢–¨: [{region_name}] ID {meta['id']} !!!", flush=True)
        try:
            # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç HTML —Ç–µ–≥–æ–≤ –¥–ª—è –ò–ò
            resp = requests.get(meta["url"], timeout=20)
            soup = BeautifulSoup(resp.text, 'html.parser')
            clean_text = soup.get_text(separator=' ', strip=True)
            
            analysis = MultiRegionAI.analyze(clean_text, region_name)
            
            # –ü–∏–Ω–≥–∏
            ping = f"<@&{ROLE_NEWS}>"
            if analysis.get("is_banner") or analysis.get("rank") == "S":
                ping += f" <@&{ROLE_BANNER}>"
            
            color = {"S": 0xFFD700, "A": 0xFF4500, "B": 0xDA70D6, "C": 0x5DADE2}.get(analysis["rank"], 0x99AAB5)
            
            payload = {
                "content": f"üì¢ **–ù–û–í–´–ô –û–¢–ß–ï–¢: –†–ï–ì–ò–û–ù {region_name.upper()}**\n{ping}",
                "embeds": [{
                    "title": f"‚Äî ‚ú¶ RANK: {analysis['rank']} | {analysis['title']} ‚ú¶ ‚Äî",
                    "description": (
                        f"**{analysis['summary']}**\n\n"
                        f"‚ï≠‚îÄ‚îÄ‚îÄ ‚≠ê **–ê–ù–ê–õ–ò–ó ({region_name})**\n"
                        f"‚îÇ {analysis['details']}\n"
                        "‚îÇ\n"
                        f"‚îÇ ‚ñ∏ **–ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï / –°–õ–ò–í–´**\n"
                        f"‚îÇ üîÆ {analysis['future']}\n"
                        "‚îÇ\n"
                        f"‚îÇ ‚ñ∏ **–í–ï–†–î–ò–ö–¢ –¢–†–ï–ù–ï–†–ê**\n"
                        f"‚îÇ ‚úÖ {analysis['verdict']}\n"
                        f"‚ï∞‚îÄ‚îÄ‚îÄ üîó [–ò–°–¢–û–ß–ù–ò–ö]({meta['url']})"
                    ),
                    "color": color,
                    "image": {"url": meta["img"]} if meta["img"] else {},
                    "footer": {"text": f"Unit: Tracen Intel ‚Ä¢ Region: {region_name} ‚Ä¢ ID: {meta['id']}"},
                    "timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat()
                }]
            }
            
            r = requests.post(WEBHOOK, json=payload)
            if r.status_code < 300:
                scanner.save_id(meta["id"])
                print(f"–û—Ç—á–µ—Ç {region_name} —É—Å–ø–µ—à–Ω–æ –¥–æ—Å—Ç–∞–≤–ª–µ–Ω –≤ Discord.", flush=True)
            else:
                print(f"–û—à–∏–±–∫–∞ Discord Webhook: {r.status_code}", flush=True)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {region_name}: {e}", flush=True)
    else:
        print(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–π –¥–ª—è {region_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.", flush=True)

if __name__ == "__main__":
    print("=== –ó–ê–ü–£–°–ö TRACEN INTELLIGENCE SYSTEM ===", flush=True)
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ø–ø–æ–Ω–∏–∏
    process_region("Japan", JP_URL, DB_JP)
    print("--- –û–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ —Å–º–µ–Ω–æ–π —Ä–µ–≥–∏–æ–Ω–∞... ---", flush=True)
    time.sleep(7)
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ì–ª–æ–±–∞–ª–∞
    process_region("Global", GLOBAL_URL, DB_GL)
    print("=== –¶–ò–ö–õ –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê –ó–ê–í–ï–†–®–ï–ù ===", flush=True)
