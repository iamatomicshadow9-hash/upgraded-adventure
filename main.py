import os
import json
import logging
import requests
import time
import datetime
import sys
from bs4 import BeautifulSoup
from groq import Groq
from typing import Dict, Any, Optional, Tuple

# ==============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –¶–ï–ù–¢–†–ê –£–ü–†–ê–í–õ–ï–ù–ò–Ø
# ==============================================================================

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger("Tracen_Global_JP_Intel")

# –†–æ–ª–∏ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
ROLE_NEWS = "1440444308506280210"
ROLE_BANNER = "1439787310831894679"

# –ö–æ–Ω—Ñ–∏–≥–∏ URL (–ü—Ä–∏–º–µ—Ä –¥–ª—è –ì–ª–æ–±–∞–ª–∞ ‚Äî –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç –∏–ª–∏ –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä)
JP_URL = "https://umamusume.jp/news/"
GLOBAL_URL = "https://uma.kakaogames.com/news/" # –ü—Ä–∏–º–µ—Ä –¥–ª—è –≥–ª–æ–±–∞–ª/–∫–æ—Ä–µ–π—Å–∫–æ–π –±–∞–∑—ã

# –§–∞–π–ª—ã –ë–î –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞
DB_JP = "last_id_jp.txt"
DB_GL = "last_id_gl.txt"

client = Groq(api_key=os.environ.get("GROQ_API_KEY"))
WEBHOOK = os.environ.get("DISCORD_WEBHOOK")

# ==============================================================================
# –ú–û–î–£–õ–¨ –ì–õ–û–ë–ê–õ–¨–ù–û–ô –†–ê–ó–í–ï–î–ö–ò
# ==============================================================================

class TracenScanner:
    def __init__(self, region_name: str, base_url: str, db_file: str):
        self.region = region_name
        self.url = base_url
        self.db_file = db_file
        self.headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}

    def get_latest(self) -> Optional[Dict[str, str]]:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –¥–≤—É—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤"""
        try:
            r = requests.get(self.url, headers=self.headers, timeout=20)
            soup = BeautifulSoup(r.text, 'html.parser')
            
            # –õ–æ–≥–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ (–∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –ø–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–∞–π—Ç–∞ —Ä–µ–≥–∏–æ–Ω–∞)
            if "jp" in self.region.lower():
                item = soup.select_one('.news-list__item')
                link = "https://umamusume.jp" + item.find('a')['href']
                img = item.find('img')['src'] if item.find('img') else None
            else:
                # –ü—Ä–∏–º–µ—Ä –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                item = soup.select_one('.article_list li') or soup.select_one('.news_item')
                link = item.find('a')['href']
                img = None # –ì–ª–æ–±–∞–ª —á–∞—Å—Ç–æ –Ω–µ –¥–∞–µ—Ç –ø—Ä–µ–≤—å—é –≤ —Å–ø–∏—Å–∫–µ
            
            news_id = link.split('=')[-1] or link.split('/')[-1]
            return {"id": news_id, "url": link, "img": img}
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è {self.region}: {e}")
            return None

    def check_new(self, current_id: str) -> bool:
        if not os.path.exists(self.db_file): return True
        with open(self.db_file, 'r') as f:
            return f.read().strip() != current_id

    def save_id(self, current_id: str):
        with open(self.db_file, 'w') as f: f.write(current_id)

# ==============================================================================
# –ò–ò-–ê–ù–ê–õ–ò–ó–ê–¢–û–† (–ö–†–û–°–°-–†–ï–ì–ò–û–ù–ê–õ–¨–ù–´–ô)
# ==============================================================================

class MultiRegionAI:
    @staticmethod
    def analyze(title: str, text: str, region: str) -> Dict[str, Any]:
        prompt = f"""
        –¢—ã ‚Äî –≥–ª–∞–≤–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ Tracen Intelligence. 
        –†–ï–ì–ò–û–ù: {region}
        –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
        –¢–µ–∫—Å—Ç: {text}

        –ó–ê–î–ê–ß–ê:
        1. –û–ø—Ä–µ–¥–µ–ª–∏ –†–∞–Ω–≥ (S/A/B/C).
        2. –≠—Ç–æ –±–∞–Ω–Ω–µ—Ä –∏–ª–∏ –≤–∞–∂–Ω—ã–π —Å–ª–∏–≤? (True/False).
        3. –ï—Å–ª–∏ —ç—Ç–æ –ì–ª–æ–±–∞–ª, –≤—Å–ø–æ–º–Ω–∏, –∫–∞–∫ —ç—Ç–æ –±—ã–ª–æ –≤ –Ø–ø–æ–Ω–∏–∏ (–µ—Å–ª–∏ –º–æ–∂–µ—à—å).
        4. –°–¥–µ–ª–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä –Ω–∞ —Ä—É—Å—Å–∫–æ–º.

        –í–ï–†–ù–ò JSON:
        {{
            "rank": "...", "title": "...", "is_banner": bool,
            "summary": "...", "details": "...", "future": "...", "verdict": "..."
        }}
        """
        res = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        return json.loads(res.choices[0].message.content)

# ==============================================================================
# –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–ë–û–†–ö–ê –ò –û–¢–ü–†–ê–í–ö–ê
# ==============================================================================

def process_region(region_name, url, db_file):
    scanner = TracenScanner(region_name, url, db_file)
    meta = scanner.get_latest()
    
    if meta and scanner.check_new(meta["id"]):
        logger.info(f"–ù–∞–π–¥–µ–Ω–∞ –Ω–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å –≤ —Ä–µ–≥–∏–æ–Ω–µ {region_name}!")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
        r = requests.get(meta["url"])
        soup = BeautifulSoup(r.text, 'html.parser')
        raw_text = soup.get_text()[:6000] # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è –ò–ò
        
        analysis = MultiRegionAI.analyze(region_name, raw_text, region_name)
        
        # –ü–∏–Ω–≥–∏
        ping = f"<@&{ROLE_NEWS}>"
        if analysis.get("is_banner") or analysis.get("rank") == "S":
            ping += f" <@&{ROLE_BANNER}>"
            
        color = {"S": 0xFFD700, "A": 0xFF4500, "B": 0xDA70D6, "C": 0x5DADE2}.get(analysis["rank"], 0x99AAB5)
        
        payload = {
            "content": f"üì¢ **–ù–û–í–´–ô –û–¢–ß–ï–¢: –†–ï–ì–ò–û–ù {region_name.upper()}**\n{ping}",
            "embeds": [{
                "title": f"‚Äî ‚ú¶ RANK: {analysis['rank']} | {analysis['title']} ‚ú¶ ‚Äî",
                "description": (
                    f"**{analysis['summary']}**\n\n"
                    f"‚ï≠‚îÄ‚îÄ‚îÄ ‚≠ê **–ê–ù–ê–õ–ò–ó ({region_name})**\n"
                    f"‚îÇ {analysis['details']}\n"
                    "‚îÇ\n"
                    f"‚îÇ ‚ñ∏ **–ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï / –°–õ–ò–í–´**\n"
                    f"‚îÇ üîÆ {analysis['future']}\n"
                    "‚îÇ\n"
                    f"‚îÇ ‚ñ∏ **–í–ï–†–î–ò–ö–¢ –¢–†–ï–ù–ï–†–ê**\n"
                    f"‚îÇ ‚úÖ {analysis['verdict']}\n"
                    f"‚ï∞‚îÄ‚îÄ‚îÄ üîó [–ò–°–¢–û–ß–ù–ò–ö]({meta['url']})"
                ),
                "color": color,
                "image": {"url": meta["img"]} if meta["img"] else {},
                "footer": {"text": f"Region: {region_name} | Tracen Intelligence Unit"},
                "timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat()
            }]
        }
        
        requests.post(WEBHOOK, json=payload)
        scanner.save_id(meta["id"])

def main():
    # –ó–∞–ø—É—Å–∫ –ø–æ –æ—á–µ—Ä–µ–¥–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞
    process_region("Japan", JP_URL, DB_JP)
    process_region("Global", GLOBAL_URL, DB_GL)

if __name__ == "__main__":
    main()
